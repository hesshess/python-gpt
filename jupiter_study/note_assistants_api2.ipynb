{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def get_duckDuckGoSearch(inputs):\n",
    "    query = inputs[\"query\"]\n",
    "    wrapper = DuckDuckGoSearchAPIWrapper(max_results=1)\n",
    "    search = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "    return search.run(query)\n",
    "\n",
    "\n",
    "def get_wikipediaSearch(inputs):\n",
    "    query = inputs[\"query\"]\n",
    "    retriever = WikipediaRetriever(top_k_results=1)\n",
    "    docs =  retriever.get_relevant_documents(query)\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    return docs_transformed[0].page_content\n",
    "\n",
    "\n",
    "def get_linkScrape(inputs):\n",
    "    link = inputs[\"link\"]\n",
    "    lst = []\n",
    "    lst.append(link)\n",
    "    loader = AsyncChromiumLoader(lst)\n",
    "    docs = loader.load()\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    return docs_transformed[0].page_content\n",
    "\n",
    "\n",
    "def saveTXTfileTool(inputs):\n",
    "    doc = inputs[\"doc\"]\n",
    "    file_path = f\"./files/{time.strftime('%H%M%S')}.txt\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(doc)\n",
    "\n",
    "\n",
    "\n",
    "functions_map = {\n",
    "    \"get_duckDuckGoSearch\": get_duckDuckGoSearch,\n",
    "    \"get_wikipediaSearch\": get_wikipediaSearch,\n",
    "    \"get_linkScrape\": get_linkScrape,\n",
    "    \"saveTXTfileTool\": saveTXTfileTool,\n",
    "}\n",
    "\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_wikipediaSearch\",\n",
    "            \"description\": \"Use this tool to research.It takes a query as an argument and return content\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query you will search for.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_duckDuckGoSearch\",\n",
    "            \"description\": \"Use this tool to find the ONLY ONE link to the most relevant result for my research.It takes a query as an argument and you return ONE link.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query you will search for.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_linkScrape\",\n",
    "            \"description\": \"You have the one website link from DuckDuckGo,Use this to get the content of the link for my research. You shoud enter the ONLY ONE link and return the content\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"link\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ONE link you will extract it's content. Example: 'https://www.wired.com/story/xz-backdoor-everything-you-need-to-know/'\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"link\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"saveTXTfileTool\",\n",
    "            \"description\": \"If you found the website link in DuckDuckGo and extracted the content or Wikipedia content, Use this to save the content to a .txt file for my research.You shoud enter long text that you extracted from the websites.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"doc\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"the content extracted from the link and you will save to .txt file.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"doc\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_6KZ58Yd9VDXmqkQzmXLdTXcs', created_at=1713130437, description=None, file_ids=[], instructions=\"You help users do research in Wikipedia and DuckDuckGo. when you find the website link from DuckDuckGo and extract the content of the link and you save the content to a .txt file for my research. Don't forget to save the .txt file\", metadata={}, model='gpt-4-1106-preview', name='Research Assistant', object='assistant', tools=[FunctionTool(function=FunctionDefinition(name='get_wikipediaSearch', description='Use this tool to research.It takes a query as an argument and return content', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for.'}}, 'required': ['query']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_duckDuckGoSearch', description='Use this tool to find the ONLY ONE link to the most relevant result for my research.It takes a query as an argument and you return ONE link.', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for.'}}, 'required': ['query']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_linkScrape', description='You have the one website link from DuckDuckGo,Use this to get the content of the link for my research. You shoud enter the ONLY ONE link and return the content', parameters={'type': 'object', 'properties': {'link': {'type': 'string', 'description': \"The ONE link you will extract it's content. Example: 'https://www.wired.com/story/xz-backdoor-everything-you-need-to-know/'\"}}, 'required': ['link']}), type='function'), FunctionTool(function=FunctionDefinition(name='saveTXTfileTool', description='If you found the website link in DuckDuckGo and extracted the content or Wikipedia content, Use this to save the content to a .txt file for my research.You shoud enter long text that you extracted from the websites.', parameters={'type': 'object', 'properties': {'doc': {'type': 'string', 'description': 'the content extracted from the link and you will save to .txt file.'}}, 'required': ['doc']}), type='function')])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai as client\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\"You help users do research in Wikipedia and DuckDuckGo. when you find the website link from DuckDuckGo and extract the content of the link and you save the content to a .txt file for my research. Don't forget to save the .txt file\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=functions,\n",
    ")\n",
    "assistant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_aMEs1bEupXXecqUyD0JVUOS4', created_at=1713130440, metadata={}, object='thread')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Research about the XZ backdoor\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_jkufaD6OSOPNiqRZg1ITdVei', assistant_id='asst_6KZ58Yd9VDXmqkQzmXLdTXcs', cancelled_at=None, completed_at=None, created_at=1713130445, expires_at=1713131045, failed_at=None, file_ids=[], instructions=\"You help users do research in Wikipedia and DuckDuckGo. when you find the website link from DuckDuckGo and extract the content of the link and you save the content to a .txt file for my research. Don't forget to save the .txt file\", last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_aMEs1bEupXXecqUyD0JVUOS4', tools=[FunctionTool(function=FunctionDefinition(name='get_wikipediaSearch', description='Use this tool to research.It takes a query as an argument and return content', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for.'}}, 'required': ['query']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_duckDuckGoSearch', description='Use this tool to find the ONLY ONE link to the most relevant result for my research.It takes a query as an argument and you return ONE link.', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for.'}}, 'required': ['query']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_linkScrape', description='You have the one website link from DuckDuckGo,Use this to get the content of the link for my research. You shoud enter the ONLY ONE link and return the content', parameters={'type': 'object', 'properties': {'link': {'type': 'string', 'description': \"The ONE link you will extract it's content. Example: 'https://www.wired.com/story/xz-backdoor-everything-you-need-to-know/'\"}}, 'required': ['link']}), type='function'), FunctionTool(function=FunctionDefinition(name='saveTXTfileTool', description='If you found the website link in DuckDuckGo and extracted the content or Wikipedia content, Use this to save the content to a .txt file for my research.You shoud enter long text that you extracted from the websites.', parameters={'type': 'object', 'properties': {'doc': {'type': 'string', 'description': 'the content extracted from the link and you will save to .txt file.'}}, 'required': ['doc']}), type='function')], usage=None, temperature=1.0, max_completion_tokens=None, max_prompt_tokens=None, truncation_strategy={'type': 'auto', 'last_messages': None}, incomplete_details=None, response_format='auto', tool_choice='auto')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run(run_id, thread_id):\n",
    "    return client.beta.threads.runs.retrieve(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def send_message(thread_id, content):\n",
    "    return client.beta.threads.messages.create(\n",
    "        thread_id=thread_id, role=\"user\", content=content\n",
    "    )\n",
    "\n",
    "\n",
    "def get_messages(thread_id):\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    for message in messages:\n",
    "        print(f\"{message.role}: {message.content[0].text.value}\")\n",
    "\n",
    "\n",
    "def get_tool_outputs(run_id, thread_id):\n",
    "    run = get_run(run_id, thread_id)\n",
    "    outputs = []\n",
    "    for action in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        action_id = action.id\n",
    "        function = action.function\n",
    "        print(f\"Calling function: {function.name} with arg {function.arguments}\")\n",
    "        args = function.arguments \n",
    "        outputs.append(\n",
    "            {\n",
    "                \"output\": functions_map[function.name](json.loads(args)),\n",
    "                \"tool_call_id\": action_id,\n",
    "            }\n",
    "        )\n",
    "        print(outputs)\n",
    "        \n",
    "    return outputs\n",
    "\n",
    "\n",
    "def submit_tool_outputs(run_id, thread_id):\n",
    "    outpus = get_tool_outputs(run_id, thread_id)\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "        tool_outputs=outpus,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'requires_action'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run(run.id, thread.id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: saveTXTfileTool with arg {\"doc\":\"Skip to main content\\n\\nOpen Navigation Menu\\n\\nMenu\\n\\nStory Saved\\n\\nTo revisit this article, visit My Profile, then View saved stories.\\n\\nClose Alert\\n\\nThe XZ Backdoor: Everything You Need to Know\\n\\n  * Security\\n  * Politics\\n  * Gear\\n  * Backchannel\\n  * Business\\n  * Science\\n  * Culture\\n  * Ideas\\n  * Merch\\n\\nStory Saved\\n\\nTo revisit this article, visit My Profile, then View saved stories.\\n\\nClose Alert\\n\\nSign In\\n\\nSUBSCRIBE\\n\\n# Get WIRED\\n\\n# for just ~~$29.99~~ $5\\n\\nSUBSCRIBE\\n\\nSearch\\n\\nSearch\\n\\n  * Security\\n  * Po\"}\n",
      "[{'output': None, 'tool_call_id': 'call_zDJkx3TotHpK2dxZzO4z0n30'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output': None, 'tool_call_id': 'call_zDJkx3TotHpK2dxZzO4z0n30'}]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tool_outputs(run.id, thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: get_linkScrape with arg {\"link\":\"https://www.wired.com/story/xz-backdoor-everything-you-need-to-know/\"}\n",
      "[{'output': 'Skip to main content\\n\\nOpen Navigation Menu\\n\\nMenu\\n\\nStory Saved\\n\\nTo revisit this article, visit My Profile, then View saved stories.\\n\\nClose Alert\\n\\nThe XZ Backdoor: Everything You Need to Know\\n\\n  * Security\\n  * Politics\\n  * Gear\\n  * Backchannel\\n  * Business\\n  * Science\\n  * Culture\\n  * Ideas\\n  * Merch\\n\\nStory Saved\\n\\nTo revisit this article, visit My Profile, then View saved stories.\\n\\nClose Alert\\n\\nSign In\\n\\nSUBSCRIBE\\n\\n# Get WIRED\\n\\n# for just ~~$29.99~~ $5\\n\\nSUBSCRIBE\\n\\nSearch\\n\\nSearch\\n\\n  * Security\\n  * Po', 'tool_call_id': 'call_Rqrn3ANm3XoC2kSL0jGquI8C'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Run(id='run_jkufaD6OSOPNiqRZg1ITdVei', assistant_id='asst_6KZ58Yd9VDXmqkQzmXLdTXcs', cancelled_at=None, completed_at=None, created_at=1713130445, expires_at=1713131045, failed_at=None, file_ids=[], instructions=\"You help users do research in Wikipedia and DuckDuckGo. when you find the website link from DuckDuckGo and extract the content of the link and you save the content to a .txt file for my research. Don't forget to save the .txt file\", last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1713130488, status='queued', thread_id='thread_aMEs1bEupXXecqUyD0JVUOS4', tools=[FunctionTool(function=FunctionDefinition(name='get_wikipediaSearch', description='Use this tool to research.It takes a query as an argument and return content', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for.'}}, 'required': ['query']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_duckDuckGoSearch', description='Use this tool to find the ONLY ONE link to the most relevant result for my research.It takes a query as an argument and you return ONE link.', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for.'}}, 'required': ['query']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_linkScrape', description='You have the one website link from DuckDuckGo,Use this to get the content of the link for my research. You shoud enter the ONLY ONE link and return the content', parameters={'type': 'object', 'properties': {'link': {'type': 'string', 'description': \"The ONE link you will extract it's content. Example: 'https://www.wired.com/story/xz-backdoor-everything-you-need-to-know/'\"}}, 'required': ['link']}), type='function'), FunctionTool(function=FunctionDefinition(name='saveTXTfileTool', description='If you found the website link in DuckDuckGo and extracted the content or Wikipedia content, Use this to save the content to a .txt file for my research.You shoud enter long text that you extracted from the websites.', parameters={'type': 'object', 'properties': {'doc': {'type': 'string', 'description': 'the content extracted from the link and you will save to .txt file.'}}, 'required': ['doc']}), type='function')], usage=None, temperature=1.0, max_completion_tokens=None, max_prompt_tokens=None, truncation_strategy={'type': 'auto', 'last_messages': None}, incomplete_details=None, response_format='auto', tool_choice='auto')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_tool_outputs(run.id, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Research about the XZ backdoor\n"
     ]
    }
   ],
   "source": [
    "get_messages(thread.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
